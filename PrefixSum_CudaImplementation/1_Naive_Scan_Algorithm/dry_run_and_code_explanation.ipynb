{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "304b4369",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Imagine You Have a List of Numbers: `[10, 20, 5, 15]`\n",
    "\n",
    "And you want to calculate a \"running total\" for each spot.\n",
    "\n",
    "* For the first number (`10`): There's nothing before it, so its running total is `0`.\n",
    "* For the second number (`20`): The number *before* it is `10`. So its running total is `10`.\n",
    "* For the third number (`5`): The numbers *before* it are `10` and `20`. So its running total is `10 + 20 = 30`.\n",
    "* For the fourth number (`15`): The numbers *before* it are `10`, `20`, and `5`. So its running total is `10 + 20 + 5 = 35`.\n",
    "\n",
    "The final list of running totals would be: `[0, 10, 30, 35]`. This is called an **\"exclusive scan\"** or **\"prefix sum\"**.\n",
    "\n",
    "---\n",
    "\n",
    "### The \"Naive\" Parallel Way (Algorithm 1)\n",
    "\n",
    "Think of it like this: You have a long line of students, each holding a number. You want each student to figure out their running total.\n",
    "\n",
    "**How it tries to work:**\n",
    "\n",
    "1.  **Everyone has a starting number.**\n",
    "2.  **Round 1:** Each student looks at the student *right next to them* (one spot back). They add that student's number to their own.\n",
    "3.  **Round 2:** Now, each student looks at the student *two spots back*. They add that student's *new total* to their *own new total*.\n",
    "4.  **Round 3:** Each student looks *four spots back*... and so on.\n",
    "\n",
    "This approach is **super fast**! If you have `N` students, it takes only a few rounds (`log2(N)` rounds). For 8 students, it's just 3 rounds.\n",
    "\n",
    "**The Problem: \"Doing Too Much Work\" (Inefficient)**\n",
    "\n",
    "* **If one student did it alone (sequentially):** They'd just go down the list, adding one number at a time. For 100 numbers, they'd do about 99 additions. Simple.\n",
    "* **With the \"Naive\" parallel method:** In *each* round, almost *all* the students are doing an addition. So, if you have 100 students and 7 rounds (`log2(100)` is about 7), they're doing roughly `100 * 7 = 700` additions in total.\n",
    "* **The Issue:** 700 additions is way more than 99! Even though it finishes faster (because many work at once), the *total amount of adding* is much higher. This is what \"not work-efficient\" means. It's like everyone on a team doing small, redundant tasks instead of just one person doing the core work efficiently.\n",
    "\n",
    "---\n",
    "\n",
    "### Why the \"Naive\" Way **Breaks** on a Real GPU\n",
    "\n",
    "Imagine a bustling factory floor (the GPU). It has many workstations (multiprocessors), and each workstation has a team of workers (your thread block).\n",
    "\n",
    "* **Small, Fast Crews (Warps):** Even within one workstation, the manager (the GPU hardware) doesn't let *everyone* work at the exact same moment. They break the team into smaller, super-fast crews (called \"warps,\" usually 32 workers). The manager rapidly switches between these crews. Crew A works for a split second, then Crew B, then Crew C, and so on.\n",
    "\n",
    "**The Catastrophic Flaw:**\n",
    "\n",
    "The \"Naive\" method says: \"Update your number *right on the spot*.\"\n",
    "\n",
    "Imagine it's Round 2:\n",
    "\n",
    "1.  **Crew A** works on numbers 1-32. They grab their \"two spots back\" numbers and update their own.\n",
    "2.  **Crew B** works on numbers 33-64. When it's their turn, a worker in Crew B needs to look at a number that Crew A just finished updating.\n",
    "\n",
    "**The Disaster:** If Crew B starts before Crew A has *completely finished updating all the numbers that Crew B might need*, then:\n",
    "* The worker in Crew B might read an **OLD, wrong number** from the previous round (before Crew A updated it).\n",
    "* Or, even worse, Crew A might be in the middle of writing a number, and Crew B tries to read it, leading to a garbled, **meaningless value** or a **crash** (the \"illegal memory access\" you saw).\n",
    "\n",
    "It's like several small teams trying to write on the same shared whiteboard simultaneously, but they're not all waiting for each other to finish their thoughts before writing. Total chaos!\n",
    "\n",
    "---\n",
    "\n",
    "### The Solution: \"Double Buffering\" (Algorithm 2)\n",
    "\n",
    "This is the fix! Instead of one whiteboard (`x[]`), we give each worker **two whiteboards** â€“ an \"In\" whiteboard and an \"Out\" whiteboard.\n",
    "\n",
    "**How it works (like in our code):**\n",
    "\n",
    "1.  **Start:** Everyone writes their initial number on their \"In\" whiteboard.\n",
    "2.  **Round 1:**\n",
    "    * All workers read from their **\"In\" whiteboards**.\n",
    "    * They do their calculation (e.g., Worker 5 looks at their \"In\" whiteboard, looks at Worker 3's \"In\" whiteboard, adds them).\n",
    "    * They write the *result* on their **\"Out\" whiteboard**.\n",
    "3.  **The \"Stop and Wait\" Moment (`__syncthreads()`):**\n",
    "    * **This is vital!** All workers stop. The manager shouts, \"Everyone! Make sure your 'Out' whiteboard is completely written and ready!\" No one moves until ALL \"Out\" whiteboards are finished.\n",
    "4.  **Swap Roles:** After everyone is done, they mentally swap: \"Okay, my 'Out' whiteboard is now my new 'In' whiteboard for the next round. And my old 'In' whiteboard is now my new 'Out' whiteboard (ready to be written on again).\"\n",
    "5.  **Round 2:**\n",
    "    * Now, everyone reads from what *was* their \"Out\" whiteboard (which is now their \"In\" for this round).\n",
    "    * They calculate.\n",
    "    * They write the result on their *new* \"Out\" whiteboard.\n",
    "6.  **\"Stop and Wait\" Again!**\n",
    "\n",
    "**Why this fixes it:**\n",
    "\n",
    "* Because of the \"Stop and Wait\" moments and having two whiteboards, when a worker reads from an \"In\" whiteboard, they are **guaranteed** that *all* the numbers on *all* \"In\" whiteboards are the final, correct results from the *previous* round. No one is touching those \"In\" whiteboards while they are being read.\n",
    "* This totally avoids the problem of reading old, garbled, or currently-being-written data.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Our Code Only Works for a \"Single Thread Block\"\n",
    "\n",
    "* The \"In\" and \"Out\" whiteboards (shared memory) are like a special, fast table that **only the workers within *that specific workstation* (thread block)** can see and use.\n",
    "* The manager's \"Stop and Wait\" command (`__syncthreads()`) *only applies to the workers in that one workstation*.\n",
    "* So, this simple code can only process a list that fits entirely on one workstation. If your list is too long (e.g., thousands of numbers), you'd need a more complex system where different workstations communicate, which is a harder problem to solve.\n",
    "\n",
    "---\n",
    "\n",
    "**In a Nutshell:**\n",
    "\n",
    "The \"Naive\" parallel scan is a clever, fast idea, but it needs **two sets of scratchpads (\"double buffering\") and mandatory \"stop and wait\" moments (`__syncthreads()`)** to work correctly on a powerful but finicky GPU, preventing different small worker teams from messing up each other's calculations. It's efficient *within* one team but not always for the *total* work done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d8df7",
   "metadata": {},
   "source": [
    "### Dry Run Example (8 Elements)\n",
    "\n",
    "Let's use the code's example: `g_idata = [1, 2, 3, 4, 5, 6, 7, 8]`\n",
    "We assume `N = 8` and `BLOCK_SIZE = 8`.\n",
    "This means `thid` will range from 0 to 7, and `block_dim_x` will be 8.\n",
    "\n",
    "**Initial State (Host `g_idata` in global memory):**\n",
    "`g_idata`: `[1, 2, 3, 4, 5, 6, 7, 8]`\n",
    "`g_odata`: `[?, ?, ?, ?, ?, ?, ?, ?]`\n",
    "\n",
    "**Inside the kernel for Block 0 (threads 0-7):**\n",
    "`thid` values: 0, 1, 2, 3, 4, 5, 6, 7\n",
    "`block_dim_x`: 8\n",
    "\n",
    "**Step 1: Initialization and First Load into `temp` (`pout = 0`, `pin = 1`)**\n",
    "`temp` array (size `2 * block_dim_x = 16` integers):\n",
    "`[?, ?, ?, ?, ?, ?, ?, ?]` (row 0, `pout`)\n",
    "`[?, ?, ?, ?, ?, ?, ?, ?]` (row 1, `pin`)\n",
    "\n",
    "Each thread executes: `temp[pout * block_dim_x + thid] = (thid > 0) ? g_idata[thid - 1] : 0;`\n",
    "\n",
    "* **thid = 0**: `temp[0] = 0`\n",
    "* **thid = 1**: `temp[1] = g_idata[0] = 1`\n",
    "* **thid = 2**: `temp[2] = g_idata[1] = 2`\n",
    "* **thid = 3**: `temp[3] = g_idata[2] = 3`\n",
    "* **thid = 4**: `temp[4] = g_idata[3] = 4`\n",
    "* **thid = 5**: `temp[5] = g_idata[4] = 5`\n",
    "* **thid = 6**: `temp[6] = g_idata[5] = 6`\n",
    "* **thid = 7**: `temp[7] = g_idata[6] = 7`\n",
    "\n",
    "`temp` after initial load (row 0 filled):\n",
    "`[0, 1, 2, 3, 4, 5, 6, 7]` (row 0, `pout`)\n",
    "`[?, ?, ?, ?, ?, ?, ?, ?]` (row 1, `pin`)\n",
    "\n",
    "`__syncthreads();` (All threads wait)\n",
    "\n",
    "**Step 2: Loop Iteration 1 (`offset = 1`)**\n",
    "\n",
    "`pout = 1 - 0 = 1`\n",
    "`pin = 1 - 1 = 0`\n",
    "\n",
    "Now, `pout` points to row 1, `pin` points to row 0.\n",
    "\n",
    "Each thread executes: `if (thid >= offset) { temp[pout*block_dim_x + thid] = temp[pin*block_dim_x + thid] + temp[pin*block_dim_x + thid - offset]; } else { temp[pout*block_dim_x + thid] = temp[pin*block_dim_x + thid]; }`\n",
    "\n",
    "| thid | `thid >= 1`? | Action                                         | Calculation ($temp[pout*8 + thid]$) | Value |\n",
    "| :--- | :----------- | :--------------------------------------------- | :---------------------------------- | :---- |\n",
    "| 0    | No           | `temp[1*8 + 0] = temp[0*8 + 0]`                | $temp[8] = temp[0] = 0$             | 0     |\n",
    "| 1    | Yes          | `temp[1*8 + 1] = temp[0*8 + 1] + temp[0*8 + 0]` | $temp[9] = temp[1] + temp[0] = 1 + 0$ | 1     |\n",
    "| 2    | Yes          | `temp[1*8 + 2] = temp[0*8 + 2] + temp[0*8 + 1]` | $temp[10] = temp[2] + temp[1] = 2 + 1$ | 3     |\n",
    "| 3    | Yes          | `temp[1*8 + 3] = temp[0*8 + 3] + temp[0*8 + 2]` | $temp[11] = temp[3] + temp[2] = 3 + 2$ | 5     |\n",
    "| 4    | Yes          | `temp[1*8 + 4] = temp[0*8 + 4] + temp[0*8 + 3]` | $temp[12] = temp[4] + temp[3] = 4 + 3$ | 7     |\n",
    "| 5    | Yes          | `temp[1*8 + 5] = temp[0*8 + 5] + temp[0*8 + 4]` | $temp[13] = temp[5] + temp[4] = 5 + 4$ | 9     |\n",
    "| 6    | Yes          | `temp[1*8 + 6] = temp[0*8 + 6] + temp[0*8 + 5]` | $temp[14] = temp[6] + temp[5] = 6 + 5$ | 11    |\n",
    "| 7    | Yes          | `temp[1*8 + 7] = temp[0*8 + 7] + temp[0*8 + 6]` | $temp[15] = temp[7] + temp[6] = 7 + 6$ | 13    |\n",
    "\n",
    "`temp` after Iteration 1:\n",
    "`[0, 1, 2, 3, 4, 5, 6, 7]` (row 0, `pin`)\n",
    "`[0, 1, 3, 5, 7, 9, 11, 13]` (row 1, `pout`)\n",
    "\n",
    "`__syncthreads();`\n",
    "\n",
    "**Step 3: Loop Iteration 2 (`offset = 2`)**\n",
    "\n",
    "`pout = 1 - 1 = 0`\n",
    "`pin = 1 - 0 = 1`\n",
    "\n",
    "Now, `pout` points to row 0, `pin` points to row 1.\n",
    "\n",
    "| thid | `thid >= 2`? | Action                                         | Calculation ($temp[0*8 + thid]$) | Value |\n",
    "| :--- | :----------- | :--------------------------------------------- | :---------------------------------- | :---- |\n",
    "| 0    | No           | `temp[0*8 + 0] = temp[1*8 + 0]`                | $temp[0] = temp[8] = 0$             | 0     |\n",
    "| 1    | No           | `temp[0*8 + 1] = temp[1*8 + 1]`                | $temp[1] = temp[9] = 1$             | 1     |\n",
    "| 2    | Yes          | `temp[0*8 + 2] = temp[1*8 + 2] + temp[1*8 + 0]` | $temp[2] = temp[10] + temp[8] = 3 + 0$ | 3     |\n",
    "| 3    | Yes          | `temp[0*8 + 3] = temp[1*8 + 3] + temp[1*8 + 1]` | $temp[3] = temp[11] + temp[9] = 5 + 1$ | 6     |\n",
    "| 4    | Yes          | `temp[0*8 + 4] = temp[1*8 + 4] + temp[1*8 + 2]` | $temp[4] = temp[12] + temp[10] = 7 + 3$ | 10    |\n",
    "| 5    | Yes          | `temp[0*8 + 5] = temp[1*8 + 5] + temp[1*8 + 3]` | $temp[5] = temp[13] + temp[11] = 9 + 5$ | 14    |\n",
    "| 6    | Yes          | `temp[0*8 + 6] = temp[1*8 + 6] + temp[1*8 + 4]` | $temp[6] = temp[14] + temp[12] = 11 + 7$ | 18    |\n",
    "| 7    | Yes          | `temp[0*8 + 7] = temp[1*8 + 7] + temp[1*8 + 5]` | $temp[7] = temp[15] + temp[13] = 13 + 9$ | 22    |\n",
    "\n",
    "`temp` after Iteration 2:\n",
    "`[0, 1, 3, 6, 10, 14, 18, 22]` (row 0, `pout`)\n",
    "`[0, 1, 3, 5, 7, 9, 11, 13]` (row 1, `pin`)\n",
    "\n",
    "`__syncthreads();`\n",
    "\n",
    "**Step 4: Loop Iteration 3 (`offset = 4`)**\n",
    "\n",
    "`pout = 1 - 0 = 1`\n",
    "`pin = 1 - 1 = 0`\n",
    "\n",
    "Now, `pout` points to row 1, `pin` points to row 0.\n",
    "\n",
    "| thid | `thid >= 4`? | Action                                         | Calculation ($temp[1*8 + thid]$) | Value |\n",
    "| :--- | :----------- | :--------------------------------------------- | :---------------------------------- | :---- |\n",
    "| 0    | No           | `temp[1*8 + 0] = temp[0*8 + 0]`                | $temp[8] = temp[0] = 0$             | 0     |\n",
    "| 1    | No           | `temp[1*8 + 1] = temp[0*8 + 1]`                | $temp[9] = temp[1] = 1$             | 1     |\n",
    "| 2    | No           | `temp[1*8 + 2] = temp[0*8 + 2]`                | $temp[10] = temp[2] = 3$            | 3     |\n",
    "| 3    | No           | `temp[1*8 + 3] = temp[0*8 + 3]`                | $temp[11] = temp[3] = 6$            | 6     |\n",
    "| 4    | Yes          | `temp[1*8 + 4] = temp[0*8 + 4] + temp[0*8 + 0]` | $temp[12] = temp[4] + temp[0] = 10 + 0$ | 10    |\n",
    "| 5    | Yes          | `temp[1*8 + 5] = temp[0*8 + 5] + temp[0*8 + 1]` | $temp[13] = temp[5] + temp[1] = 14 + 1$ | 15    |\n",
    "| 6    | Yes          | `temp[1*8 + 6] = temp[0*8 + 6] + temp[0*8 + 2]` | $temp[14] = temp[6] + temp[2] = 18 + 3$ | 21    |\n",
    "| 7    | Yes          | `temp[1*8 + 7] = temp[0*8 + 7] + temp[0*8 + 3]` | $temp[15] = temp[7] + temp[3] = 22 + 6$ | 28    |\n",
    "\n",
    "`temp` after Iteration 3:\n",
    "`[0, 1, 3, 6, 10, 14, 18, 22]` (row 0, `pin`)\n",
    "`[0, 1, 3, 6, 10, 15, 21, 28]` (row 1, `pout`)\n",
    "\n",
    "`__syncthreads();`\n",
    "\n",
    "**Step 5: Loop Termination**\n",
    "\n",
    "The loop condition `offset < block_dim_x` (`8 < 8`) is now false. The loop terminates.\n",
    "\n",
    "**Step 6: Write Output to Global Memory**\n",
    "\n",
    "The final `pout` is 1.\n",
    "Each thread executes: `g_odata[thid] = temp[pout * block_dim_x + thid];`\n",
    "\n",
    "* **thid = 0**: `g_odata[0] = temp[1*8 + 0] = temp[8] = 0`\n",
    "* **thid = 1**: `g_odata[1] = temp[1*8 + 1] = temp[9] = 1`\n",
    "* **thid = 2**: `g_odata[2] = temp[1*8 + 2] = temp[10] = 3`\n",
    "* **thid = 3**: `g_odata[3] = temp[1*8 + 3] = temp[11] = 6`\n",
    "* **thid = 4**: `g_odata[4] = temp[1*8 + 4] = temp[12] = 10`\n",
    "* **thid = 5**: `g_odata[5] = temp[1*8 + 5] = temp[13] = 15`\n",
    "* **thid = 6**: `g_odata[6] = temp[1*8 + 6] = temp[14] = 21`\n",
    "* **thid = 7**: `g_odata[7] = temp[1*8 + 7] = temp[15] = 28`\n",
    "\n",
    "**Final `g_odata` (correct exclusive scan):** `[0, 1, 3, 6, 10, 15, 21, 28]`\n",
    "\n",
    "---\n",
    "\n",
    "### Concepts Used in the Code (Simplified)\n",
    "\n",
    "1.  **Exclusive Scan (Prefix Sum):**\n",
    "    * **Concept:** Imagine you have a list of numbers. An \"exclusive scan\" creates a new list where each number is the *sum of all numbers that came before it* in the original list. The number at the current position itself is *not included* in its own sum.\n",
    "    * **Example:** If your input is `[A, B, C, D]`, the exclusive scan result is `[0, A, A+B, A+B+C]`. For `[1, 2, 3, 4]`, it's `[0, 1, 3, 6]`.\n",
    "    * **Why used?** It's a foundational operation in parallel computing for tasks like parallel sorting, stream compaction (removing unwanted elements), polynomial evaluation, dynamic memory allocation, and more. It allows operations that normally require sequential processing to be broken down and done in parallel.\n",
    "\n",
    "2.  **CUDA Kernel (`__global__`) and GPU Threads (`threadIdx.x`, `blockDim.x`):**\n",
    "    * **Concept:** A CUDA kernel is a special function designed to run on the GPU. When you launch a kernel, you're telling the GPU to execute many copies of this function in parallel.\n",
    "    * **Threads:** Each copy of the kernel runs as a \"thread.\" Imagine a massive team of workers.\n",
    "    * **`threadIdx.x`:** Each worker (thread) has a unique ID within its immediate supervisor's group (a \"thread block\"). This ID is `threadIdx.x`. It tells each worker which specific piece of the data it's responsible for.\n",
    "    * **`blockDim.x`:** This tells you how many workers are in each group (thread block). In our example, `blockDim.x = 8`, meaning there are 8 threads in our single block.\n",
    "\n",
    "3.  **Shared Memory (`__shared__`) and Double Buffering:**\n",
    "    * **Concept:** Shared memory is like a very fast, on-chip scratchpad or whiteboard that all workers within a single thread block can use. It's much faster than accessing data from the main storage room (global memory).\n",
    "    * **`extern __shared__`:** This means the size of the whiteboard isn't fixed in the code itself. Instead, you tell the GPU how big to make it when you launch the kernel. This makes the kernel more flexible.\n",
    "    * **Double Buffering (`pout`, `pin`):** Imagine having two whiteboards (or two sections on one big whiteboard). In each step of our calculation, some workers read from \"whiteboard A\" while others write to \"whiteboard B.\" Then, for the next step, they swap roles: the workers who were writing on B now read from B, and the ones reading from A now write on A. This prevents workers from accidentally reading data that's still being updated by another worker, ensuring calculations are based on completed data from the previous step. It's crucial for avoiding race conditions in parallel algorithms.\n",
    "\n",
    "4.  **Synchronization (`__syncthreads()`):**\n",
    "    * **Concept:** This is like a \"meeting point\" for all workers within a single group (thread block). When a worker reaches `__syncthreads()`, it stops and waits until *every other worker in its group* also reaches that same point. Only then can all workers proceed together.\n",
    "    * **Why used?** In parallel algorithms, it's vital to ensure that certain steps are completed by all workers before the next step begins. For example, you need to make sure all data is loaded onto the whiteboard before any worker starts calculating with it. And after one round of calculations, you need everyone to finish writing their results before moving on to the next round of calculations using those results. `__syncthreads()` guarantees this order.\n",
    "\n",
    "5.  **Logarithmic (Tree-based) Parallel Algorithm (`offset *= 2`):**\n",
    "    * **Concept:** This is the clever part that makes the scan fast in parallel. Instead of each worker summing up everything from the beginning (which would be sequential), the algorithm works like a series of increasingly wide additions, similar to how matches progress in a tournament bracket.\n",
    "    * **How it works:**\n",
    "        * **Round 1 (offset=1):** Each element adds the value from the element *just before it*.\n",
    "        * **Round 2 (offset=2):** Each element adds the value from the element *two positions before it* (which already contains a partial sum from Round 1).\n",
    "        * **Round 3 (offset=4):** Each element adds the value from the element *four positions before it* (which contains an even larger partial sum from Round 2).\n",
    "        * This continues, doubling the `offset` each time. This allows a list of `N` items to be scanned in `log2(N)` steps, which is extremely fast for large `N` compared to `N` sequential steps.\n",
    "\n",
    "This combination of shared memory for fast local access, double buffering for data consistency, synchronization for ordered execution, and a logarithmic algorithm structure is what makes this parallel exclusive scan highly efficient on GPUs."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
